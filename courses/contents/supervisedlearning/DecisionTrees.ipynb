{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f955fb-6dbd-4966-8b6c-fdb9ff86bcc3",
   "metadata": {},
   "source": [
    "# Decision Trees & Ensemble Methods \n",
    "\n",
    "This notebook focuses on:\n",
    "- model training and **cross-validation**,\n",
    "- **Decision Trees** (classification & regression),\n",
    "- ensemble methods: **Bagging**, **Random Forests**, **AdaBoost**.\n",
    "\n",
    "**Learning goals**\n",
    "- Understand K-fold cross-validation and hyperparameter tuning.\n",
    "- Train and interpret Decision Trees for classification and regression.\n",
    "- Apply and compare ensembles for improved performance.\n",
    "- Practice with small synthetic supply-chain examples (late delivery classification, lead-time forecasting).\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook structure**\n",
    "1. Quick refresher: decision trees (concepts & hyperparameters)  \n",
    "2. Cross-validation: why and how (practical)  \n",
    "3. Classification example — will delivery be late? (synthetic supply-chain dataset)  \n",
    "4. Regression example — lead time forecasting (synthetic)  \n",
    "5. Ensembles: Bagging / Random Forests / AdaBoost  \n",
    "6. Practical exercises and quiz (novice friendly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a70c7-1339-4086-be58-fe7670b464f6",
   "metadata": {},
   "source": [
    "## I. What is a Decision Tree?\n",
    "\n",
    "A Decision Tree splits the feature space into regions using simple rules like if/else rules, we talk about binary decision trees in this case. For **classification**, leaves predict class or labels of instances based on the most represented group in a leaf.\n",
    "For **regression**, leaves return a numeric value (e.g. mean value of all instances in a leaf).\n",
    "Depending on the type fo tree you aim to build, the metric you are goinfg to optimize is different. In classifcation tasks, you use the entropy or Gini index. In regression, you will learn the different rules using the variance.\n",
    "\n",
    "\n",
    "- Advantages of decision trees: interpretable, handles mixed features, little preprocessing.\n",
    "- Disadvantages of this model : can overfit (high variance), unstable small data changes.\n",
    "\n",
    "**Key hyperparameters**\n",
    "\n",
    "The following criterion are most common hyper-parameters of decision trees that benefit tuned during the learning stage. \n",
    "\n",
    "- `max_depth`: maximum depth of the tree (controls complexity).\n",
    "- `min_samples_split`: minimum number of samples required to split an internal node.\n",
    "- `min_samples_leaf`: minimum samples required to be at a leaf node.\n",
    "- `criterion`: splitting criterion (`gini`, `entropy` for classification; `mse`/`friedman_mse` for regression).\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4dc2f-1aca-4160-a028-a9aea6f9fb9d",
   "metadata": {},
   "source": [
    "Let us first have a look at the decision boundaries of a decision tree wigh respect to the choice of the hyperparameter `max_depth on the following simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d8626c-ad26-4fae-8362-5c6a07d320f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = make_moons(noise=0.3, random_state=42, n_samples=300)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap='coolwarm', edgecolor='k')\n",
    "plt.title(\"Dataset : Two Moons\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88380335-bf8e-4c8a-9f9a-addd1937b298",
   "metadata": {},
   "source": [
    "$$  $$\n",
    "\n",
    "**Question 1** : Run the following code and observe the performances of the decision tree. What can you say, in your opition about the depth of the tree regarding the performances?\n",
    "\n",
    "$$  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec0c9d-d502-4de9-88b1-566015bb5503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy score on the test set :\", accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b8725-5dae-448c-a95d-986979653325",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 2** : Plot the decision tree using the following `plot_tree(clf, filled=True)`. What can you say about the structure?\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068ecf7-37dd-43a9-9eb5-1df1256a73b9",
   "metadata": {},
   "source": [
    "We can also represent the decision boundaries using the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1be4ec-929f-4c15-a207-58b820dac78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_decision_boundary(model, X, y, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap='coolwarm', alpha=0.3)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolor='k', s=30)\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "# Example : \n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "plot_decision_boundary(clf, X, y, ax, \"Decision Boundaries of a Decision Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26bbf3c-de8e-4d09-9013-31ab0edbf45a",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 3** : What can you say about the Decision Boundaries, is it consistent with the assumption formulated at Question 1?\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257bad1a-5494-4cd0-aa79-a21921e55553",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_values = [1, 2, 3, 5, None]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(depth_values), figsize=(20, 4))\n",
    "\n",
    "for ax, d in zip(axes, depth_values):\n",
    "    model = DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Performances\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    # Graphs with scores\n",
    "    title = f\"max_depth={d}\\nTrain={train_acc:.2f} | Test={test_acc:.2f}\"\n",
    "    \n",
    "    plot_decision_boundary(model, X, y, ax, title=title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a16ed48-68f6-49a8-bda7-71c681d309b2",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 4**: What do you notice about the train and test scores as the depth increases?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 5**: What is the optimal structure in terms of depth according to the results obtained?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 6**: Why does the tree with `max_depth=None` often have very good performance on the training set but poor performance on the test set?\n",
    "\n",
    "$$ $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5556bfdc-b0c3-4237-8562-910a9ec99a02",
   "metadata": {},
   "source": [
    "We now want to study the influence of other hyperparameters on the model's performance. More specifically, we aim to examine the effects of the following hyperparameters:\n",
    "\n",
    "* `min_samples_split`: minimum number of samples required to split a node\n",
    "* `min_samples_leaf`: minimum number of samples required to be at a leaf node\n",
    "\n",
    "For this, we will use the code below and fix the tree depth to $5$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ca39a-af6a-40c3-9145-6dd4c55e72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "plot_decision_boundary(clf, X, y, title=\"min_samples_leaf=5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4a466f-375f-4789-8cf9-5733efcced36",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 7**: Use the previous code to illustrate the impact of these two hyperparameters and study their effect.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 8**: Compare the decision boundaries with `min_samples_leaf=1` and `min_samples_leaf=10`.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 9**: What is the influence of `min_samples_split`?\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7871cb3b-a77e-4735-aa0b-8bc83980e9b2",
   "metadata": {},
   "source": [
    "## II.  Cross-validation\n",
    "\n",
    "**Why use CV?**\n",
    "\n",
    "A single train/test split can give misleading performance estimates due to random sampling. A K-fold CV provides a more reliable estimate of generalization by averaging performance across K splits and can be used for hyper-parameter tuning.\n",
    "\n",
    "**Common approaches**\n",
    "\n",
    "Several type of Cross-validation can be used, we present thme for the sake of completeness but the last one corresponds to the one presented in class. \n",
    "\n",
    "- K-Fold CV: split data into K parts; rotate which part is the validation set.\n",
    "- Stratified K-Fold: preserves class proportions for classification (recommended if classes are imbalanced for instance).\n",
    "- GridSearchCV: runs CV while searching over hyperparameter combinations.\n",
    "\n",
    "**Practical tips for Supply Chain**\n",
    "\n",
    "Use stratified CV if predicting binary outcomes like 'late' vs 'on-time', however, for time dependent data (lead times over time), use time-aware validation (not covered in depth here).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889025de-64ec-474f-836e-eedc0e4d6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports and helper functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "np.random.seed(0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "\n",
    "def show_confusion(y_true, y_pred, labels=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('True'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c8d3cf-471f-4546-9e0d-6fdedb6e36e8",
   "metadata": {},
   "source": [
    "## III. Decision Tree for a Classification Task\n",
    "\n",
    "**Scenario:** \n",
    "\n",
    "Predict if a delivery will be **late** (1) or **on-time** (0) using features available before shipment:\n",
    "\n",
    "- `distance_km` — distance to destination\n",
    "- `order_size` — number of items in the order\n",
    "- `hub_load` — load index at the origin hub\n",
    "- `supplier_reliability` — historical reliability score (0 to 1)\n",
    "\n",
    "We build a synthetic dataset to train a Decision Tree and evaluate via cross-validation and a test split.\n",
    "\n",
    "The code below will not print anything, it is just used to generate some data and introduce a fucntion that will be used to show the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60e407-aacf-4b93-a4d0-c51704d79cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Synthetic dataset that mimics supply chain factors\n",
    "n = 600\n",
    "X, y = make_classification(\n",
    "    n_samples=n, n_features=4, n_informative=3, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.7, 0.3], class_sep=1.0, random_state=42\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(X, columns=['distance_km', 'order_size', 'hub_load', 'supplier_reliability'])\n",
    "\n",
    "# Transform features to realistic ranges for interpretation\n",
    "df['distance_km'] = np.round((df['distance_km'] - df['distance_km'].min()) /\n",
    "                             (df['distance_km'].max() - df['distance_km'].min()) * 500, 1)\n",
    "df['order_size'] = np.round((df['order_size'] - df['order_size'].min()) /\n",
    "                            (df['order_size'].max() - df['order_size'].min()) * 100).astype(int)\n",
    "df['hub_load'] = np.clip((df['hub_load'] - df['hub_load'].min()) /\n",
    "                         (df['hub_load'].max() - df['hub_load'].min()) * 10, 0, 10).round(2)\n",
    "df['supplier_reliability'] = np.clip((df['supplier_reliability'] - df['supplier_reliability'].min()) /\n",
    "                                     (df['supplier_reliability'].max() - df['supplier_reliability'].min()), 0, 1).round(2)\n",
    "df['late'] = y\n",
    "\n",
    "# Show the first rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eec706-a485-4d7b-9614-1987bd4fddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X = df[['distance_km', 'order_size', 'hub_load', 'supplier_reliability']]\n",
    "y = df['late']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=0)\n",
    "\n",
    "# Baseline Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy (baseline tree):', round(accuracy_score(y_test, y_pred), 3))\n",
    "print('\\nClassification report:\\n', classification_report(y_test, y_pred))\n",
    "show_confusion(y_test, y_pred, labels=[0,1])\n",
    "\n",
    "# Visualize a shallow tree (for readability, show top levels)\n",
    "plt.figure(figsize=(12,6))\n",
    "plot_tree(dt, feature_names=X.columns, class_names=['on-time', 'late'], filled=True, max_depth=3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8c5e3-7020-4e61-8336-199397355b96",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 10 :** Describe the performances of this model.\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c693d7-f919-4f1a-831a-fc1e709c5087",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with GridSearchCV\n",
    "\n",
    "We tune `max_depth` and `min_samples_leaf` using stratified 5-fold CV to find a tree with better generalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b3d63-be44-40dd-aa4e-10ac2fe3ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 6, None],\n",
    "    'min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best params:', gs.best_params_)\n",
    "print('Best CV accuracy:', round(gs.best_score_, 3))\n",
    "\n",
    "best_dt = gs.best_estimator_\n",
    "y_pred_gs = best_dt.predict(X_test)\n",
    "print('Test accuracy (best estimator):', round(accuracy_score(y_test, y_pred_gs), 3))\n",
    "show_confusion(y_test, y_pred_gs, labels=[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd3410-8c44-45bb-b1d7-564df781fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for the best decision tree\n",
    "\n",
    "fi = pd.Series(best_dt.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(6,4))\n",
    "fi.plot(kind='bar')\n",
    "plt.title('Feature importances (Decision Tree)')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()\n",
    "\n",
    "print(fi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab22eda-01eb-453b-a356-202652170226",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 11 :** What is the most important variable?\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41ff8e-be4c-400b-b1e6-f64ddf433f40",
   "metadata": {},
   "source": [
    "## IV. Regression Trees\n",
    "\n",
    "We now aim to illustrate how a regression tree works.  \n",
    "\n",
    "### A. Illustration on a toy example \n",
    "\n",
    "For this, we will consider the dataset below, which follows a sinusoidal pattern. In the following, we will focus only on the parameter that controls the depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9e53b-c463-46c6-86c6-c5511b2a55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "X = np.sort(10 * rng.rand(120, 1), axis=0)\n",
    "y = np.sin(X).ravel() + 0.3 * rng.randn(120)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(X, y, edgecolor='k')\n",
    "plt.title(\"Simulated data with noise\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fae308-ec15-441f-ab5f-a368728f7db9",
   "metadata": {},
   "source": [
    "We will use the code below to study the impact of tree depth on model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3f66a-4335-45c6-865a-55bfbb66748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "depths = [1, 3, 5, 10, None]\n",
    "X_plot = np.arange(0.0, 10.0, 0.01)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(X_train, y_train, edgecolor='k', label=\"Train\", alpha=0.7)\n",
    "plt.scatter(X_test, y_test, edgecolor='k', label=\"Test\", alpha=0.7, marker='s')\n",
    "\n",
    "for d in depths:\n",
    "    reg = DecisionTreeRegressor(max_depth=d, random_state=42)\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = reg.predict(X_train)\n",
    "    y_pred_test = reg.predict(X_test)\n",
    "    y_pred_plot = reg.predict(X_plot)\n",
    "    \n",
    "    # Errors\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    \n",
    "    # Models and scores graphs\n",
    "    plt.plot(X_plot, y_pred_plot, label=f\"max_depth={d}\\nMSE train={mse_train:.2f}, test={mse_test:.2f}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Impact of depth on the regression model\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c809438b-4f91-49d5-aec5-970f7187f8ef",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 12**: What do you notice about the evolution of MSE_train and MSE_test as max_depth increases?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 13**: Which depth seems most suitable for the bias/variance trade-off?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 14**: What happens if we leave max_depth=None (unlimited tree)?\n",
    "$$ $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded2e672-a481-4e46-83e7-b0a833fa67df",
   "metadata": {},
   "source": [
    "### B.. A Regression Tree for Lead time forecasting\n",
    "\n",
    "**Scenario:** \n",
    "\n",
    "Predict delivery lead time (days) using:\n",
    "\n",
    "- `distance_km`, `order_size`, `hub_load`, `supplier_reliability`\n",
    "- `seasonality_index` (e.g., peak season increases lead time)\n",
    "\n",
    "We create a simple synthetic regression dataset, train a Decision Tree Regressor, and evaluate with RMSE and R² as it was done in the linear regression model.\n",
    "\n",
    "The code below is used to generate a synthetic dataset that will be used for the illustration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ab05a-e6e6-4b04-80e9-f2dc44a742bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic regression dataset for lead times\n",
    "n = 600\n",
    "rng = np.random.RandomState(1)\n",
    "distance = rng.uniform(10, 800, size=n)\n",
    "order_size = rng.poisson(20, size=n)\n",
    "hub_load = rng.uniform(0, 10, size=n)\n",
    "supplier_reliability = rng.uniform(0.6, 1.0, size=n)\n",
    "seasonality_index = rng.choice([0.8, 1.0, 1.2], size=n, p=[0.3, 0.4, 0.3])\n",
    "\n",
    "# Simple generative model for lead time (days)\n",
    "lead_time = 1 + 0.01 * distance + 0.05 * order_size + 0.2 * hub_load \\\n",
    "            - 2.0 * supplier_reliability + 1.5 * (seasonality_index - 1.0) \\\n",
    "            + rng.normal(scale=2.0, size=n)\n",
    "lead_time = np.clip(lead_time, 0.5, None)\n",
    "\n",
    "df_reg = pd.DataFrame({\n",
    "    'distance_km': np.round(distance,1),\n",
    "    'order_size': order_size,\n",
    "    'hub_load': np.round(hub_load,2),\n",
    "    'supplier_reliability': np.round(supplier_reliability,2),\n",
    "    'seasonality_index': seasonality_index,\n",
    "    'lead_time': np.round(lead_time,2)\n",
    "})\n",
    "df_reg.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c6efe1-7057-46f0-9776-5b8f2710ce91",
   "metadata": {},
   "source": [
    "We repeat exactly the same steps as for the Classification Tree to study the performances of the Regression Tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6bd1e5-bf9c-4786-9b51-1c9bafed045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "Xr = df_reg.drop(columns=['lead_time'])\n",
    "yr = df_reg['lead_time']\n",
    "\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr, test_size=0.25, random_state=0)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=0)\n",
    "dtr.fit(Xr_train, yr_train)\n",
    "yr_pred = dtr.predict(Xr_test)\n",
    "\n",
    "print('RMSE (baseline tree):', round(root_mean_squared_error(yr_test, yr_pred), 3))\n",
    "print('R2:', round(r2_score(yr_test, yr_pred), 3))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plot_tree(dtr, feature_names=Xr.columns, rounded=True, max_depth=3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e45248c-91a6-4da4-a557-861340d4642b",
   "metadata": {},
   "source": [
    "We also go one with the cross-validaton procedure to optimize the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03370c9-ca52-48df-b26a-96096f3b2e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "param_grid_r = {'max_depth': [2, 3, 4, 6, None], 'min_samples_leaf': [1, 2, 5, 10]}\n",
    "cv_r = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "gsr = GridSearchCV(DecisionTreeRegressor(random_state=0), param_grid_r,\n",
    "                   scoring='neg_mean_squared_error', cv=cv_r, n_jobs=-1)\n",
    "gsr.fit(Xr_train, yr_train)\n",
    "\n",
    "print('Best params (reg):', gsr.best_params_)\n",
    "best_dtr = gsr.best_estimator_\n",
    "yr_pred_gs = best_dtr.predict(Xr_test)\n",
    "\n",
    "print('Test RMSE (best reg tree):', round(root_mean_squared_error(yr_test, yr_pred_gs), 3))\n",
    "print('Test R2:', round(r2_score(yr_test, yr_pred_gs), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f6208-c8cc-4b01-9886-62eea03de7fc",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 15 :** Which variable has the most importance? Use the same code as for classification tree to answer this question.\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b2bf51-8c70-4f34-81cb-d50925f99abc",
   "metadata": {},
   "source": [
    "## V. Ensemble Methods\n",
    "\n",
    "Ensemble methods are techniques that involve combining multiple models to generate a new model that is potentially more *performant* but also more *robust*.  \n",
    "This combination is generally done in two ways:\n",
    "\n",
    "* via **bagging**\n",
    "* or via **boosting**\n",
    "\n",
    "The first approach, *i.e.*, bagging, helps reduce *variance*, making the model more robust while preserving its performance. The second approach, *i.e.*, boosting, helps reduce the component of error known as bias, making models more performant while maintaining their robustness.\n",
    "\n",
    "We could also study another ensemble approach called **stacking**.  \n",
    "While bagging and boosting combine multiple models of the same type, *i.e.*, several SVMs or several shallow trees, stacking involves combining multiple models of different types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ab395-07e6-4ad6-910f-b4de685c6084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.datasets import make_regression, make_moons\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084439c-bc27-4c87-9031-6e9dd7b5f060",
   "metadata": {},
   "source": [
    "## A. Bagging: Variance Reduction\n",
    "\n",
    "A flagship algorithm based on bagging is the random forest.  \n",
    "In a few words, bagging methods consist of combining models that are learned from different information, *i.e.* from different samples.  \n",
    "These models are then combined, usually by averaging, to create a single high-performing model.\n",
    "\n",
    "We consider a training sample $S$ and perform the following procedure $T$ times, where $T$ represents the number of models we want to learn:  \n",
    "(i) draw a sample $S_t$ with replacement from $S$,  \n",
    "(ii) train a model $h_t$ using the sample $S_t$.\n",
    "\n",
    "Once the $T$ models are learned, we obtain a global model $H_T$ that can be written as:\n",
    "\n",
    "$$ H_T = \\dfrac{1}{T}\\sum_{t=1}^T h_t. $$\n",
    "\n",
    "The simplest example is the combination of trees to build a *random forest* [Breiman, 2001].\n",
    "\n",
    "Before combining the models, we will briefly review decision trees and then look to combine models.  \n",
    "Consider the dataset below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb3e9f-a664-42ef-a280-b21b9aa7f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelets\n",
    "rng = np.random.RandomState(42)\n",
    "X = np.sort(10 * rng.rand(200, 1), axis=0)\n",
    "y = np.sin(X).ravel() + 0.4 * rng.randn(200)\n",
    "y_true = np.sin(np.linspace(0, 10, 500).reshape(-1, 1)).ravel()  # vraie fonction\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_plot = np.linspace(0, 10, 500).reshape(-1, 1)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(X_train, y_train, label=\"Train\", color=\"blue\", alpha=0.6)\n",
    "plt.scatter(X_test, y_test, label=\"Test\", color=\"red\", alpha=0.6)\n",
    "plt.plot(X_plot, y_true, color=\"green\", linewidth=2, label=\"sin(x)\")\n",
    "plt.legend()\n",
    "plt.title(\"Simulated data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f3e3b-7aaa-4732-8c71-a696289d0651",
   "metadata": {},
   "source": [
    "We will now look at the predictions made by a regression tree of depth $10$.  \n",
    "Note that we could also do this with any other model, such as a high-degree polynomial linear regression, if we wanted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfaac89-6ae1-4ef6-b00b-6110c203971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = tree.predict(X_train)\n",
    "y_pred_test = tree.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "X_plot = np.linspace(0, 10, 500).reshape(-1, 1)\n",
    "y_plot = tree.predict(X_plot)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X_train, y_train, label=\"Train\", color=\"blue\", alpha=0.5)\n",
    "plt.plot(X_plot, y_true, color=\"green\", linewidth=2, label=\"in(x)\")\n",
    "plt.plot(X_plot, y_plot, label=f\"Arbre seul\\nMSE train={mse_train:.2f} / test={mse_test:.2f}\", color=\"black\")\n",
    "plt.legend()\n",
    "plt.title(\"Predictionof a single tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e296ad-8b3d-4126-b864-31b55905f09e",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 16**: Compare the prediction function to the true value. What do you observe?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 17**: What happens if we increase the depth of the tree? Which error changes the most (train or test) as the complexity increases?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "We will now focus on the bagging method, for which a direct implementation is proposed and illustrated below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0eec2e-4081-4be3-b789-3ded2d50c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging with several trees \n",
    "\n",
    "n_trees = 10\n",
    "\n",
    "bagging = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(max_depth=10),\n",
    "    n_estimators=n_trees,\n",
    "    random_state=42,\n",
    "    bootstrap=True\n",
    ")\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = bagging.predict(X_train)\n",
    "y_pred_test = bagging.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X_train, y_train, color=\"blue\", alpha=0.5, label=\"Train\")\n",
    "plt.scatter(X_test, y_test, color=\"red\", alpha=0.5, label=\"Test\")\n",
    "plt.plot(X_plot, y_true, color=\"green\", linewidth=2, label=\"Fonction sin(x)\")\n",
    "plt.plot(X_plot, bagging.predict(X_plot), color=\"black\",\n",
    "         label=f\"Bagging with {n_trees:.2f} trees \\nMSE train={mse_train:.2f} / test={mse_test:.2f}\")\n",
    "plt.legend()\n",
    "plt.title(\"Réduction de variance par Bagging\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635c09ec-9e40-4046-b62a-02142f383303",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 18**: Compare the MSE between the single tree and the bagging model.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 19**: What is the major difference you observe in the prediction curve?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 20**: Explain why bagging reduces the variance of the model. For this, we will compare the error of the ensemble method to the average error of the individual predictors.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "We now want to compare the behavior of different trees learned on bootstrap samples and our regressor obtained using the bagging method.  \n",
    "We will therefore create different bootstrap samples as explained at the beginning of this section.  \n",
    "As a reminder, a bootstrap sample $S_b$ is a sample of the same size as the original sample $S$, obtained by drawing with replacement from the examples in $S$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946825dc-c156-4a90-80f0-fb4f7606058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i in range(10):\n",
    "    # Boostrap Sampling\n",
    "    X_boot, y_boot = resample(X, y, replace=True, random_state=i)\n",
    "    \n",
    "    # Learning Tree\n",
    "    tree = DecisionTreeRegressor(max_depth=10)\n",
    "    tree.fit(X_boot, y_boot)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = tree.predict(X_plot)\n",
    "    predictions.append(y_pred)\n",
    "    \n",
    "    # Plots\n",
    "    plt.plot(X_plot, y_pred, color=\"gray\", alpha=0.3)\n",
    "\n",
    "#plt.plot(X_plot, bagging.predict(X_plot), color=\"red\", linewidth=2, label=\"Bagging (moyenne)\")\n",
    "y_mean = np.mean(predictions, axis=0)\n",
    "plt.plot(X_plot, y_mean, color=\"black\", linewidth=2, label=\"Mean of trees (Bagging)\")\n",
    "plt.plot(X_plot, y_true, color=\"green\", linewidth=2, label=\"sin(x)\")\n",
    "plt.title(\"Several trees VS Mean (Bagging)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5fb3b0-169e-4164-b8ec-0688778909be",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 21**: What do you notice about the gray curves representing the predictions of the individual trees?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 22**: Why are these trees different from each other?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 23**: In what way is the average of the trees (curve shown in black) more stable?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 24**: How does this average illustrate the variance reduction provided by bagging?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 25**: Try modifying `n_estimators` and `max_depth` and observe how this affects the stability of the final model.\n",
    "\n",
    "$$ $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76167e7-4802-43a2-a489-953366b23538",
   "metadata": {},
   "source": [
    "We now want to compare the performance of a decision tree with that of a random forest for a classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48b72e-78cc-4d34-89ea-64a6ab9fe997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(noise=0.4, random_state=42, n_samples=300)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "forest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "acc_tree = accuracy_score(y_test, tree.predict(X_test))\n",
    "acc_forest = accuracy_score(y_test, forest.predict(X_test))\n",
    "\n",
    "print(f\"Accuracy arbre : {acc_tree:.3f}\")\n",
    "print(f\"Accuracy forêt : {acc_forest:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f664bf2-a950-43c8-83c7-f13dd34eda39",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 26**: What performance difference do you observe?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 27**: Why is the random forest more robust?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 28**: What happens if we reduce `n_estimators`?\n",
    "\n",
    "$$ $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f87e89-143c-4916-a250-6edf37d2a011",
   "metadata": {},
   "source": [
    "## B. Boosting: Bias Reduction\n",
    "\n",
    "Previously, models were trained independently of each other. The idea of boosting is to break this independence.\n",
    "\n",
    "We assume that the models learned have low predictive power, and we want to create a combination of these models so that the combined model performs better.  \n",
    "To do this, we learn our models iteratively in such a way that the model learned at the current iteration can correct the errors made by the previous model.\n",
    "\n",
    "The first boosting algorithm developed to address this problem is the *Adaboost* algorithm [Freund, 1999].\n",
    "\n",
    "#### Principle of Boosting\n",
    "\n",
    "Let’s now look at the different steps of an Adaboost algorithm.\n",
    "\n",
    "We initially have our sample $S$ with $m$ examples $(x_i, y_i)$, and all data points have **the same weight**, i.e., the same importance.\n",
    "\n",
    "We now consider how a hypothesis $h_{t+1}$ is learned based on the performance of the classifier $h_t$.  \n",
    "At step $t$ of the algorithm, the examples have weights $w^{(t)}_i$.  \n",
    "A hypothesis $h_t$ is then learned, and we can evaluate its classification error rate $\\varepsilon_t$:\n",
    "\n",
    "$$ \\varepsilon_t = \\sum_{i=1}^m w^{(t)}_i I_{\\left\\{ h_t(x_i)y_i <0\\right\\}}, $$\n",
    "\n",
    "where $I$ denotes the indicator function. From this error, we determine a quantity $\\alpha_t$ defined by:\n",
    "\n",
    "$$ \\alpha_t = \\dfrac{1}{2}\\ln \\left(\\dfrac{1-\\varepsilon_t}{\\varepsilon_t}\\right), $$\n",
    "\n",
    "which quantifies the importance of hypothesis $h_t$ in the final decision, i.e., it defines a weight on the learned classifier.\n",
    "\n",
    "The rest of the procedure consists of finding **a good reweighting of the examples** so that the hypothesis learned at the next iteration focuses on the errors made by the current hypothesis. This is done using the following update:\n",
    "\n",
    "$$ w^{(t+1)}_i = w^{(t)}_i\\dfrac{\\exp(-\\alpha_ty_ih_t(x_i))}{Z_t}, $$\n",
    "\n",
    "where $Z_t$ is a normalization factor ensuring that the weights form a distribution over the examples.  \n",
    "Later, we will see that this normalization factor is given by $Z_t = 2\\sqrt{\\varepsilon_t(1-\\varepsilon_t)}.$  \n",
    "The reweighting function increases the weight of misclassified examples and decreases the weight of correctly classified examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d5410a-f292-4746-9022-3fced14cb306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "X, y = make_moons(noise=0.25, random_state=0, n_samples=300)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Visualize decision boundaries\n",
    "def plot_decision_boundary(model, X, y, ax, title=None):\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap='coolwarm', alpha=0.3)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolor='k')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "# List of number of trees for visualization\n",
    "n_estimators_list = [1, 5, 20, 100]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(n_estimators_list), figsize=(20,4))\n",
    "for ax, n in zip(axes, n_estimators_list):\n",
    "    ada = AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=1),\n",
    "        n_estimators=n,\n",
    "        learning_rate=0.5,\n",
    "        random_state=42\n",
    "    )\n",
    "    ada.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, ada.predict(X_test))\n",
    "    plot_decision_boundary(ada, X, y, ax, title=f\"{n} itérations\\nAcc={acc:.2f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8bbb0f-80b9-4874-a7b4-621669d7381e",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 29**: How does the decision boundary evolve with the number of iterations?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 30**: What happens if the *learning_rate* is too high? Start by experimenting with this parameter and observe its impact on the decision boundaries to answer the question.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "Recall that our ensemble model $H_T$ is the combination of several models $h_t$ that are learned iteratively.  \n",
    "We have\n",
    "\n",
    "$$H_T = \\sum_{t=0}^T \\alpha_t h_t$$\n",
    "\n",
    "The *learning_rate* parameter actually multiplies the values of $\\alpha_t$ such that $\\alpha_t \\leftarrow \\alpha_t \\times learning\\_rate$.  \n",
    "An illustration of the impact of this parameter on the model’s performance is shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99342e-ac61-492a-acef-277551f96ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_moons(n_samples=300, noise=0.25, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Deux modèles avec learning_rate différents\n",
    "ada1 = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=10,\n",
    "    learning_rate=0.1,  # faible\n",
    "    random_state=42\n",
    ")\n",
    "ada2 = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=10,\n",
    "    learning_rate=1.0,  # standard\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada1.fit(X_train, y_train)\n",
    "ada2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Acc faible LR:\", accuracy_score(y_test, ada1.predict(X_test)))\n",
    "print(\"Acc LR=1 :\", accuracy_score(y_test, ada2.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
