{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224d7d45-1565-4b79-8f68-9c96efa4438b",
   "metadata": {},
   "source": [
    "# TD : Modèles et apprentissage en Machine Learning \n",
    "\n",
    "L'objectif de cette séance pratique et de regarder comment implémenter les différents modèles présentés lors des différentes séancs à l'aide de Python.\n",
    "\n",
    "Nous commencerons notre travail sur des jeux de donnéessynthétiques afin de visualiser les résultats des différents modèles, puis on étudiera l'impact des hyper-paramètres sur les performances du modèles.\n",
    "\n",
    "Dans un second temps, on cherchera ensuite à optimiser ces hyper-paramètres en mettant en place a cross-validation de ces derniers puis nous finirons par développer un protocole complet d'apprentissage et de comparaison des modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee333a-2d6a-4b85-a509-4bebc62a31c9",
   "metadata": {},
   "source": [
    "# I. Visualisation des sorties d'un modèle de SVM : linéaire et non linéaire\n",
    "\n",
    "On commence par regarder le comportement d'un SVM mais aussi la façon d'apprendre ce dernier. Pour cela, nous aurons besoin des librairies suivantes de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ecae0-7e86-4b63-8e81-9a2d025a15f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4346ac-81a9-4d64-b9fc-d0ce0acda483",
   "metadata": {},
   "source": [
    "On commence par charger notre jeu de données. On travaillera avec un jeu de données classique **iris**.\n",
    "Ce jeu de données est un jeu de données multi-classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f747cf28-ce84-4bb4-a792-b098597039eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2] # On va garder uniquement les deux premières variables\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40698bf9-d0b8-4e1f-82c4-54ca02cbaaac",
   "metadata": {},
   "source": [
    "## A. Apprentissage d'un SVM linéaire\n",
    "\n",
    "L'apprentissage d'un SVM se fait avec la fonction SVC qui dépend de plusieurs paramètres dont le \"noyau\" que l'on souhaite employer. Ici, on souhaite travailler avec un noyau linéaire dans un premier temps.\n",
    "\n",
    "Pour apprendre un modèle de SVM, on utilisera la commande suivante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd6b36-3245-4c55-baf4-73afad5d67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_linear = SVC(kernel = \"linear\")\n",
    "clf_linear.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ec007-6247-4c86-ab53-d4d388207bf1",
   "metadata": {},
   "source": [
    "On va maintenant chercher à représenter graphiquement les sorties du modèle et on regardera ensuite la performance de ce dernier à l'aide de différentes librairies sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f6f1c-b912-4906-aee3-b9a25ebc8d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va créer un maillage de notre espace de représentation des données\n",
    "h = 0.02  # finesse du maillage\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df0ca3b-96d7-4bb3-9452-bd01cbf897d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On représente maintenant les frontières de décision \n",
    "\n",
    "Z_linear = clf_linear.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z_linear = Z_linear.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z_linear, cmap=plt.cm.RdBu_r, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu_r)\n",
    "plt.title('SVM Linéaire')\n",
    "plt.xlabel('Sepal Length')\n",
    "plt.ylabel('Sepal Width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de939c-0fea-41b0-b68e-2e4875d3594a",
   "metadata": {},
   "source": [
    "On pourra également regarder les performances du modèle en étudiant sa matrice de confusion et calculer différentes métriques de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb0414-0906-43f3-801a-50656431fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On commence par regarder les prédictions effectuées par notre modèle sur les données.\n",
    "\n",
    "prediction = clf_linear.predict(X)\n",
    "\n",
    "# On peut maintenant regarder la matrice de confusion de notre matrice et en faire une représentation graphique\n",
    "\n",
    "confusion_pred = confusion_matrix(y, prediction) # Mettre les arguments dans l'ordre (true_label, predicted_label)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_pred,\n",
    "                              display_labels=clf_linear.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ccb8d-c939-42a2-9181-b4279da8bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'accuracy\n",
    "\n",
    "accuracy_score(y,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713d116-1f16-490e-af63-042d546c0fd3",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 1 :** Refaire le même procédé avec le jeu de données généré par le code ci-dessous\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34529230-d0bd-4a8d-8c3b-d986e7da3f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=500, noise=0.25, random_state=1)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu_r)\n",
    "plt.title('SVM Linéaire')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a418f5-cfc9-42fd-9ed9-4cb752c09726",
   "metadata": {},
   "source": [
    "Pour le moment, nous n'avons regarder qu'un problème particulier du SVM.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 2** : Rappeler le problème d'optimisation du SVM ainsi que la signification de l'hyperparamètre associé au problème.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "On va maintenant chercher à regarder l'influence de cet hyperparamètre sur les performances du modèle sur notre jeu de données mais aussi l'impact que cela peut avoir sur la frontière de décision. On commence donc par se donner une grille de valeurs de l'hyperparamètre C afin d'étudier son impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943440a5-9b09-4272-8225-f022f64ecf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, :2] # On va garder uniquement les deux premières variables\n",
    "y = iris.target\n",
    "\n",
    "C_values = [0.001, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61676f54-a891-4e25-a3c5-f6bcb443aa6a",
   "metadata": {},
   "source": [
    "On va maitenant regarder graphiquement et empiriquement l'influence de cet hyper-paramètre C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c9d93-f859-4de7-a2cf-de5e6ecfb7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "for i, C in enumerate(C_values, 1):\n",
    "    # Apprentissage du modèle et évaluation des performances\n",
    "    \n",
    "    clf_lin = SVC(kernel='linear', C = C)\n",
    "    clf_lin.fit(X, y)\n",
    "\n",
    "    prediction = clf_lin.predict(X)\n",
    "    acc_lin = accuracy_score(y,prediction)\n",
    "\n",
    "    # On va créer à nouveau notre même fenêtre graphique\n",
    "    h = 0.02  \n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Plot decision boundary\n",
    "    plt.subplot(2, 3, i)\n",
    "    Z_lin = clf_lin.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z_lin = Z_lin.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z_lin, cmap=plt.cm.RdBu_r, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu_r)\n",
    "    plt.title(f'SVM Linéaire avec C={C} et Acc = {acc_lin}')\n",
    "    plt.xlabel('X_1')\n",
    "    plt.ylabel('X_2')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae7423-2f32-447a-8f4c-ca5fbf893487",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 4**: Rappeler la définition d'un point support de modèle de SVM et mettre en évidence ces derniers sur le jeu de données précédent.\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9206e817-3817-4502-87dd-1658ae7f8506",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 5**: Faire le lien entre l'hyperparamètre C et le nombre de points supports du modèle. Est-ce une bonne chose un nombre important \n",
    "de points supports ? Quels sont les avantages/inconvénients d'avoir de petites ou grandes valeurs de C ?\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa56c04-5bed-447c-9a48-86cc51af3d92",
   "metadata": {},
   "source": [
    "## B. Apprentissage d'un SVM Gaussien (Noyau RBF)\n",
    "\n",
    "Pour le moment, nous nous sommes uniquement intéressé au problème du SVM linéaire dont la formulation a été rappelée dans la deuxième question. On va maintenant reprendre notre jeu de données des lunes et on peut remarquer que ce dernier est difficilement linéaire séparable.\n",
    "Il est donc nécessaire d'employer des approches plus complexes basées sur les méthodes à noyaux. Le noyau le plus couramment utilisé est le noyau gaussien défini par :\n",
    "$$ $$\n",
    "\n",
    "$$\\forall x,x' \\in\\mathbb{R}^d, \\quad k(x,x') = \\exp(-\\gamma \\Vert x-x' \\Vert^2_2).$$\n",
    "\n",
    "Dans ce cas là, nous avons un nouvel hyperparamètre à optimiser qui est l'hyperparamètre $gamma$. \n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 6**: Obsever graphiquement l'influence de cet hyperparamètre $\\gamma$ sur la frontière de décision de votre modèle et sur les performances de ce dernier en fixant la valeur de $C$ à $1$.\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa09f2-65b9-4bef-92a5-eb468d51d047",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 7**: A nouveau, regarder comment évolue le nombre de points supports en fonction de la valeur de $\\gamma$.\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313076f5-37ac-48ce-87c1-13515044a5d4",
   "metadata": {},
   "source": [
    "# II. Apprentissage d'un modèle et cross-validation des hyper-paramètres\n",
    "\n",
    "On souhaite maintenant regarder comment cross-valider les hyper-paramètres liés à ces deux modèles afin de pouvoir comparer leur performances et de déterminer le modèle le plus approprié sur un jeu de données. La première étape consiste à créer nos jeux de données Train et Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f02c2-79b2-438e-862b-e83b2c4f630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0071fed-cb10-427e-8600-15e2d6a50368",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 1**: Télécharger le jeu de données breast_cancer et séparer votre jeu de données en deux ensembles train et test. On prendra soin de conserver 75% des données pour l'entraînement.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "On considère, pour simplifier notre modèle de SVM linéaire pour lequel on cherche à optimiser l'hyperparamètre $C$. \n",
    "Pour cela, nous devons créer différents folds à partir de notre ensemble d'entraînement afin de faire la cross-validation de notre modèle.\n",
    "\n",
    "$$ $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b44110-5616-457f-8f52-b0c850eba9c7",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 2**: Donnez vous une liste de valeurs de $C$ et créer vos différents groupes d'apprentissage et de validation qui vous permettront de déterminer la meilleur valeur de l'hyperparamètre. On pensera à utiliser la fonction *StratifiedKFold*\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d438d4-592f-43bf-a29c-6e4502d43937",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 3**: Ecrire une boucle permettant de trouver le meilleur hyperparamètre pour votre problème de classification. Attention, rappelez-vous, il vous faudra penser à normaliser les données à chaque itération de la cross-validation. Il faudra ensuite extraire le mielleur hyperparamètre après la cross-validation.\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d834e5e-1902-4850-8ae3-184a9bd0af6b",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 4**: Finir votre procédure et evaluer les performances de votre modèle sur l'ensemble test. Est-ce que cela vous a permis d'apprendre le meilleur modèle, *i.e.* est-ce que vous avez retenu la valeur de $C$ qui permet d'optimiser le score sur l'ensemble test ?\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1888d-1a44-432a-bf25-ded0b0b00b76",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "Il y bien sûr des moyens beaucoup plus rapides pour faire de la Cross-Validation à l'aide du processus présenté ci-dessous\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1131e6c-2e8d-4abf-8731-f02e0fd788ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7875db-efd2-4fd7-bf33-39019507a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.1,1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv = 5)\n",
    "clf.fit(iris.data, iris.target)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aed794-1b77-4165-b09a-5b5788a3fb17",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 5**: Essayez maintenant d'écrire un code complet qui vous permettra de comparer les performances d'un SVM Linéaire et d'un SVM Gaussien sur ce jeux de données.\n",
    "  \n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce9ca29-2859-4d17-aa65-9efe26a4f98b",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 6**: Appliquer la même procédure mais sur un ensemble de jeux de données.\n",
    "  \n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de5b9e-89c2-4178-a927-5409a94a5353",
   "metadata": {},
   "source": [
    "# III. Arbres de décisions\n",
    "\n",
    "Dans cette partie, on va étudier le comportement des arbres de décisions dans le cadre d'un problème de classification et d'un problème de régression. On cherchera à mettre en évidence le rôle des différents hyper-paramètres et leur impact mais aussi comment évaluer l'importance de chaque variable dans la prise de décision.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eed57b-83e6-4cbe-b8f4-0bb61ea6b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons, make_regression, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac11749-4b0c-4692-9eb5-a87e78f7117e",
   "metadata": {},
   "source": [
    "## A. Classification sur un jeu de données simulées\n",
    "\n",
    "On va travailler sur le jeu de données classique des lunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b543f-0336-4423-aa2e-823e76e28de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(noise=0.3, random_state=42, n_samples=300)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap='coolwarm', edgecolor='k')\n",
    "plt.title(\"Jeu de données : Deux Lunes\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9df32-1137-42b8-87ee-2843e0a6e80c",
   "metadata": {},
   "source": [
    "$$  $$\n",
    "\n",
    "**Question 1** : Exécuter le code ci-dessous et détermienr les performances de l'arbre. Que pouvez dire de la profondeur de l'arbre au regard des performances obtenues ?\n",
    "\n",
    "$$  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2268a4bd-6065-406c-82da-069fb060c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy sur le test :\", accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615c5dc-2b6f-4f9b-af04-208076563f4e",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 2** : Affichez l'arbre de décision avec la commande  \"plot_tree(clf, filled=True)\" et commentez la structure.\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a954974-8d00-44e2-9d39-0c4682d8d20b",
   "metadata": {},
   "source": [
    "On peut également représenter la frontière de décision de notre arbre de décision avec le code ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e60fe-6d7d-4f29-9dc0-c755d68fa79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap='coolwarm', alpha=0.3)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolor='k', s=30)\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "# Exemple : \n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "plot_decision_boundary(clf, X, y, ax, \"Frontière de décision (arbre par défaut)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802702e7-6b5d-42e4-845f-bf8d80fb1316",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 3** : Observer les frontières de décisions obtenues. Est-ce que cela valide l'hypothèse formulée à la question 1.\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7c42b-9ee7-4d38-b5a4-4b410d05aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_values = [1, 2, 3, 5, None]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(depth_values), figsize=(20, 4))\n",
    "\n",
    "for ax, d in zip(axes, depth_values):\n",
    "    model = DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calcul des performances\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    # Titre avec les scores\n",
    "    title = f\"max_depth={d}\\nTrain={train_acc:.2f} | Test={test_acc:.2f}\"\n",
    "    \n",
    "    plot_decision_boundary(model, X, y, ax, title=title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f42b32-896c-4b4b-879e-29efce55572c",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 4** : Que remarquez-vous sur les scores train et test quand la profondeur augmente ?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 5** : Quelle est la structure optimale, en terme de profondeur d'après les résultats obtenus ?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 6** : Pourquoi l’arbre avec max_depth=None a-t-il souvent une très bonne performance sur le train mais une mauvaise sur le test ?\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee887c-505a-4b46-b8ab-174a6da5da34",
   "metadata": {},
   "source": [
    "On cherche maitenant à étudier l'influence des autres hyper-paramètres sur les performances du modèles. Plus précisément on cherche à étudier les effets des hyper-paramètres :\n",
    "\n",
    "\n",
    "* min_samples_split : nombre minimal d’échantillons pour diviser un nœud\n",
    "* min_samples_leaf  : nombre minimal d’échantillons par feuille\n",
    "\n",
    "Pour cela, on utilisera le code ci-dessous et fixera la profondeur de l'arbre à $5$.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca1018-b9e9-4441-9468-36d91eb4ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "plot_decision_boundary(clf, X, y, title=\"Effet de min_samples_leaf=5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a240f2dd-d32f-4e55-a260-5ca50e958355",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 7** : On utilisera le code précédent pour illustrer l'impact de ces deux hyper-paramètres et étudier leur effet.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 8** : Comparez les frontières avec min_samples_leaf=1 et min_samples_leaf=10.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 9** : Quelle est l’influence de min_samples_split ?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db62ba4-037f-4aca-ac82-1390c25332d1",
   "metadata": {},
   "source": [
    "## B. Arbres de régression\n",
    "\n",
    "On cherche maitenant à illustrer le fonctionnement d'un arbre de régression. \n",
    "Pour cela, on va considérer le jeu de données ci-dessous, qui se présente sous la forme d'une sinusoïde et, dans la suite, on s'intéressera uniquemeet au paramètre qui gère la profondeur de l'arbre.O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c527977-689d-472a-91ea-41fb6f8eddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "X = np.sort(10 * rng.rand(120, 1), axis=0)\n",
    "y = np.sin(X).ravel() + 0.3 * rng.randn(120)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(X, y, edgecolor='k')\n",
    "plt.title(\"Données de régression bruitées\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f6f2ea-b8f7-45e2-8f92-841ae1f3463e",
   "metadata": {},
   "source": [
    "On va utiliser le code ci-dessous pour étudier l'impact de la profondeur de l'arbre sur les performances du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08846ad-6d75-4255-81c1-90da812e7f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "depths = [1, 3, 5, 10, None]\n",
    "X_plot = np.arange(0.0, 10.0, 0.01)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(X_train, y_train, edgecolor='k', label=\"Train\", alpha=0.7)\n",
    "plt.scatter(X_test, y_test, edgecolor='k', label=\"Test\", alpha=0.7, marker='s')\n",
    "\n",
    "for d in depths:\n",
    "    reg = DecisionTreeRegressor(max_depth=d, random_state=42)\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédictions\n",
    "    y_pred_train = reg.predict(X_train)\n",
    "    y_pred_test = reg.predict(X_test)\n",
    "    y_pred_plot = reg.predict(X_plot)\n",
    "    \n",
    "    # Calcul des erreurs\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    \n",
    "    # Affichage du modèle et des scores\n",
    "    plt.plot(X_plot, y_pred_plot, label=f\"max_depth={d}\\nMSE train={mse_train:.2f}, test={mse_test:.2f}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Impact de la profondeur sur la régression par arbre de décision\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c74c8-1da3-4470-af89-0f7fde928df5",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 1** : Que remarquez-vous sur l’évolution des erreurs MSE_train et MSE_test lorsque max_depth augmente ? \n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 2** : Quelle profondeur semble la plus adaptée au compromis biais/variance ?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 3** : Que se passe-t-il si on laisse max_depth=None (arbre non limité) ?\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645053c-1164-4b4e-ba92-211efccd4a1e",
   "metadata": {},
   "source": [
    "## C. Importance des variables\n",
    "\n",
    "Dans cette dernière partie, on va chercher à étudier l'importance des différentes variables dans la prise de décision sur un problème de classification. Pour cela, on va considérer le jeu de données *Breast Cancer* et entrainer un arbre de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1dd13-4477-42ff-8ffb-b60aef4150b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "feature_names = data.feature_names\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=importances[indices], y=np.array(feature_names)[indices])\n",
    "plt.title(\"Importance des variables - arbre de décision\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57263a8b-ba6b-443b-8255-1eaaa502391a",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 1** : Quelles variables sont les plus importantes pour la classification ?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 2** : Que se passe-t-il si on augmente max_depth ?\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b77e29-3850-4c48-a5b6-b83bf0f00b6b",
   "metadata": {},
   "source": [
    "Les arbres sont des modèles importants car ces derniers sont explicables. \n",
    "En effet, on est capable grâce à la succession de règles de comprendre le cheminement qui a mené à la prise de décision, *i.e.*, à la la classification d'un exemple. \n",
    "De plus, nous sommes capables de déterminer quelles sont les variables clefs pour la prise de décision, ce qui peut être intéressant lorsque l'on cherche à limiter le nombre d'informations sur lesquelles doit se baser notre décision. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e34279d-7a7f-4394-beb7-92b01ffcd7aa",
   "metadata": {},
   "source": [
    "# IV. Méthodes ensemblistes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1b7ed4-d83d-47ea-a4a6-98add7909df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.datasets import make_regression, make_moons\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b5c42-f243-4dc4-863e-27999c65821a",
   "metadata": {},
   "source": [
    "## A. Bagging : réduction de la variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f1cae-d552-437c-9dc7-0d5d5f5d1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données sinusoïdales\n",
    "rng = np.random.RandomState(42)\n",
    "X = np.sort(10 * rng.rand(200, 1), axis=0)\n",
    "y = np.sin(X).ravel() + 0.4 * rng.randn(200)\n",
    "y_true = np.sin(np.linspace(0, 10, 500).reshape(-1, 1)).ravel()  # vraie fonction\n",
    "\n",
    "# Découpage train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "np.linspace(0, 10, 500).reshape(-1, 1)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(X_train, y_train, label=\"Train\", color=\"blue\", alpha=0.6)\n",
    "plt.scatter(X_test, y_test, label=\"Test\", color=\"red\", alpha=0.6)\n",
    "plt.plot(X_plot, y_true, color=\"green\", linewidth=2, label=\"Fonction sin(x)\")\n",
    "plt.legend()\n",
    "plt.title(\"Jeu de données sinusoïdal bruité\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5bdaab-0755-4602-9982-82351201de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = tree.predict(X_train)\n",
    "y_pred_test = tree.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "X_plot = np.linspace(0, 10, 500).reshape(-1, 1)\n",
    "y_plot = tree.predict(X_plot)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X_train, y_train, label=\"Train\", color=\"blue\", alpha=0.5)\n",
    "plt.plot(X_plot, y_true, color=\"green\", linewidth=2, label=\"Fonction sin(x)\")\n",
    "plt.plot(X_plot, y_plot, label=f\"Arbre seul\\nMSE train={mse_train:.2f} / test={mse_test:.2f}\", color=\"black\")\n",
    "plt.legend()\n",
    "plt.title(\"Prédiction d'un arbre de régression seul\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f97d7-cccd-4d14-93e0-ac35fcde6801",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 1** : Comparer la fonction de prédiction à la vraie valeur, que constatez-vous ?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 2** : Que se passe-t'il si l'on augmente la profondeur de l'arbre ? Quelle erreur change le plus (train ou test) lorsque la complexité augmente ?\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715cfba-bf20-4268-be5c-e5c1a8dcb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging avec plusieurs arbres\n",
    "bagging = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(max_depth=10),\n",
    "    n_estimators=10,\n",
    "    random_state=42,\n",
    "    bootstrap=True\n",
    ")\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_train = bagging.predict(X_train)\n",
    "y_pred_test = bagging.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X_train, y_train, color=\"blue\", alpha=0.5, label=\"Train\")\n",
    "plt.scatter(X_test, y_test, color=\"red\", alpha=0.5, label=\"Test\")\n",
    "plt.plot(X_plot, y_true, color=\"green\", linewidth=2, label=\"Fonction sin(x)\")\n",
    "plt.plot(X_plot, bagging.predict(X_plot), color=\"black\",\n",
    "         label=f\"Bagging (50 arbres)\\nMSE train={mse_train:.2f} / test={mse_test:.2f}\")\n",
    "plt.legend()\n",
    "plt.title(\"Réduction de variance par Bagging\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3b320-5b27-4c37-b7d7-380e0d5bd166",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 3** : Comparez les MSE entre l’arbre seul et le bagging.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 4** : Quelle est la différence majeure que vous observez dans la courbe de prédiction ?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 5** : Expliquez pourquoi le bagging réduit la variance du modèle. Pour cela on va comparer l'erreur de la méthode ensembliste à la moyenne des erreurs des predicteurs individuels.\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37cb096-bc40-481d-af5e-5d2b8d501499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i in range(10):\n",
    "    # Tirage bootstrap\n",
    "    X_boot, y_boot = resample(X, y, replace=True, random_state=i)\n",
    "    \n",
    "    # Apprentissage d’un arbre sur cet échantillon\n",
    "    tree = DecisionTreeRegressor(max_depth=10)\n",
    "    tree.fit(X_boot, y_boot)\n",
    "    \n",
    "    # Prédictions sur la grille\n",
    "    y_pred = tree.predict(X_plot)\n",
    "    predictions.append(y_pred)\n",
    "    \n",
    "    # On affiche chaque prédiction d’arbre en transparence\n",
    "    plt.plot(X_plot, y_pred, color=\"gray\", alpha=0.3)\n",
    "\n",
    "#plt.plot(X_plot, bagging.predict(X_plot), color=\"red\", linewidth=2, label=\"Bagging (moyenne)\")\n",
    "y_mean = np.mean(predictions, axis=0)\n",
    "plt.plot(X_plot, y_mean, color=\"black\", linewidth=2, label=\"Moyenne des arbres (Bagging)\")\n",
    "plt.plot(X_plot, y_true, color=\"green\", linewidth=2, label=\"Fonction sin(x)\")\n",
    "plt.title(\"Superposition de plusieurs arbres vs moyenne (Bagging)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b607550-6f8b-4732-9824-6e7113f27da2",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 6** : Que remarquez-vous sur les courbes grises représentant les prédictions des arbres individuels ?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 7** : Pourquoi ces arbres sont-ils différents les uns des autres ?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 8** : En quoi la moyenne des arbres (courbe représentée en noire) est-elle plus stable ?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 9** : Comment cette moyenne illustre-t-elle la réduction de variance apportée par le bagging ? \n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 10** : Essayez de modifier n_estimators et max_depth et regarder comment cela impact la stabilité du modèle final ?\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c92ac-fcc0-4ad0-8824-6238c277801f",
   "metadata": {},
   "source": [
    "On souhaite maintenant comparer les performances d'un arbre à celle d'une forêt aléatoire pour un problème de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d978eec-afad-4bea-ae48-4b4a95c1e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(noise=0.4, random_state=42, n_samples=300)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "forest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "acc_tree = accuracy_score(y_test, tree.predict(X_test))\n",
    "acc_forest = accuracy_score(y_test, forest.predict(X_test))\n",
    "\n",
    "print(f\"Accuracy arbre : {acc_tree:.3f}\")\n",
    "print(f\"Accuracy forêt : {acc_forest:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72af68-9b49-4c4b-97e5-8dec5edac8dc",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "**Question 11** : Quelle différence de performance observez-vous ?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 12** : Pourquoi la forêt aléatoire est-elle plus robuste ?\n",
    "\n",
    "$$ $$\n",
    "\n",
    "**Question 13** : Que se passe-t-il si on réduit n_estimators ?\n",
    "\n",
    "$$ $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b57daf-c3bb-418a-98af-54a420a5062b",
   "metadata": {},
   "source": [
    "Dans une dernière partie, on souhaite étudier ce que l'on appelle l'erreur OOB (*Out of Bag*) qui est l'erreur utiilisée pour effectuer la cross-validation des modèles de forêt aléatoire. \n",
    "\n",
    "Note à moi même : regarder comment mettre ce concept en avant ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2997a4-c84a-4b9a-ae18-4bd4e0827b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A méditer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046cea2-b040-4121-a850-d6b085621f5b",
   "metadata": {},
   "source": [
    "## B. Boosting : réduction du biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bdaf8e-07c0-491c-9000-9ff4eb96eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "X, y = make_moons(noise=0.25, random_state=0, n_samples=300)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fonction pour visualiser les frontières\n",
    "def plot_decision_boundary(model, X, y, ax, title=None):\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap='coolwarm', alpha=0.3)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolor='k')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "# Visualisation pour plusieurs nombres d'estimateurs\n",
    "n_estimators_list = [1, 5, 20, 100]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(n_estimators_list), figsize=(20,4))\n",
    "for ax, n in zip(axes, n_estimators_list):\n",
    "    ada = AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=1),\n",
    "        n_estimators=n,\n",
    "        learning_rate=0.5,\n",
    "        random_state=42\n",
    "    )\n",
    "    ada.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, ada.predict(X_test))\n",
    "    plot_decision_boundary(ada, X, y, ax, title=f\"{n} itérations\\nAcc={acc:.2f}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845638c-6c59-4996-a528-4c62cb25cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_moons(n_samples=300, noise=0.25, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Deux modèles avec learning_rate différents\n",
    "ada1 = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.1,  # faible\n",
    "    random_state=42\n",
    ")\n",
    "ada2 = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0,  # standard\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada1.fit(X_train, y_train)\n",
    "ada2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Acc faible LR:\", accuracy_score(y_test, ada1.predict(X_test)))\n",
    "print(\"Acc LR=1 :\", accuracy_score(y_test, ada2.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b389a66-4bdc-41e9-b26b-4c83045718f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
